---
title: "[Mutual Information for Explainable Deep Learning of Multiscale Systems]"
collection: publications
permalink: /publication/2020-01-01-paper-4
excerpt: 
date: 2020-01-01
venue: 'Journal of Computational Physics'
paperurl: 'https://arxiv.org/abs/2009.04570'
citation: '<b>S. Taverniers</b>, E.J. Hall, M.A. Katsoulakis, and D.M. Tartakovsky. <i>Article submitted to Journal of Computational Physics</i> (2020).'
---

## Abstract

Timely completion of design cycles for multiscale and multiphysics systems ranging from consumer electronics to hypersonic vehicles relies on rapid simulation-based prototyping. The latter typically involves high-dimensional spaces of possibly correlated control variables (CVs) and quantities of interest (QoIs) with non-Gaussian and/or multimodal distributions. We develop a model-agnostic, moment-independent global sensitivity analysis (GSA) that relies on differential mutual information to rank the effects of CVs on QoIs. Large amounts of data, which are necessary to rank CVs with confidence, are cheaply generated by a deep neural network (DNN) surrogate model of the underlying process. The DNN predictions are made explainable by the GSA so that the DNN can be deployed to close design loops. Our information-theoretic framework is compatible with a wide variety of black-box models. Its application to multiscale supercapacitor design demonstrates that the CV rankings facilitated by a domain-aware Graph-Informed Neural Network are better resolved than their counterparts obtained with a physics-based model for a fixed computational budget. Consequently, our information-theoretic GSA provides  an ``outer loop'' for accelerated product design by identifying the most and least sensitive input directions and performing subsequent optimization over appropriately reduced parameter subspaces.