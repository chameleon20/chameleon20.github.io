<!---
---
title: "[Mutual Information for Explainable Deep Learning of Multiscale Systems]"
collection: publications
permalink: /publication/2020-01-01-paper-4
excerpt: 
date: 2020-01-01
venue: 'Journal of Computational Physics'
paperurl: 'https://arxiv.org/abs/'
citation: 'E.J. Hall, <b>S. Taverniers</b>, M.A. Katsoulakis, and D.M. Tartakovsky. <i>Article submitted to Journal of Computational Physics</i> (2020).'
---

## Abstract

Timely completion of design cycles for multiscale and multiphysics systems ranging from consumer elec-tronics to hypersonic vehicles relies on rapid simulation-based prototyping.   The latter typically involveshigh-dimensional spaces of possibly correlated control variables (CVs) and quantities of interest (QoIs) withnon-Gaussian and/or multimodal distributions.  We develop a model-agnostic, moment-independent globalsensitivity analysis (GSA) that relies on differential mutual information to rank the effects of CVs on QoIs.Large amounts of data, which are necessary to rank CVs with confidence, are cheaply generated by a deepneural network (DNN) surrogate model of the underlying process. The DNN predictions are made explain-able by the GSA so that the DNN can be deployed to close design loops.  Our information-theoretic frame-work is compatible with a wide variety of black-box models.  Its application to multiscale supercapacitordesign demonstrates that the CV rankings facilitated by a domain-aware Graph-Informed Neural Networkare better resolved than their counterparts obtained with a physics-based model for a fixed computationalbudget.  Consequently, our information-theoretic GSA provides an “outer loop” for accelerated product de-sign by identifying the most and least sensitive input directions and performing subsequent optimization overappropriately reduced parameter subspaces.--->